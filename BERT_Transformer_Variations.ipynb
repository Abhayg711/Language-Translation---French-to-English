{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UopcBh2tB-Y9",
        "mz0m1t6YqXux",
        "i--hFY4c-WhZ",
        "Uip6GhzDOtEj",
        "DebbPsjET71d",
        "2NkTwyRXBC18",
        "1jU-bp-aD0cX",
        "8TpVZqLCIDV_"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5f5076bb1bd74930881fb9d380b3a01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_46416536060e4425bb0d7a32fb3767bd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5ae265bc9d349f897af9b48a57ef672",
              "IPY_MODEL_1253aa8e39644b4289adca15c948ae16"
            ]
          }
        },
        "46416536060e4425bb0d7a32fb3767bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5ae265bc9d349f897af9b48a57ef672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8be4a9b317364a01bf9b8775356c2094",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ef5641d72da46f99f60651441a5b2a9"
          }
        },
        "1253aa8e39644b4289adca15c948ae16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d9fc0c7eb7174d85b42d02fd525dbf34",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 785kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5135f004b7fa471f824a70c9b8010409"
          }
        },
        "8be4a9b317364a01bf9b8775356c2094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ef5641d72da46f99f60651441a5b2a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d9fc0c7eb7174d85b42d02fd525dbf34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5135f004b7fa471f824a70c9b8010409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0367fa064d5a4942aba0bfee2f5aa0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f7fba19c6cfc4702a3117b70b5d79ff3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1992c17ce4844c3ea229c9de1fe0b312",
              "IPY_MODEL_c18a08b476794fbba72019ed0793c797"
            ]
          }
        },
        "f7fba19c6cfc4702a3117b70b5d79ff3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1992c17ce4844c3ea229c9de1fe0b312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0490b885ee9d4e2d908fd91a5afea4e6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07d43af87346420b98bc55010b8b4952"
          }
        },
        "c18a08b476794fbba72019ed0793c797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_30a0f0aefc054ef49e17f1f0f2d6e26a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 2.14kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_231bca6c28144f2798c8f3cafac87ff6"
          }
        },
        "0490b885ee9d4e2d908fd91a5afea4e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07d43af87346420b98bc55010b8b4952": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30a0f0aefc054ef49e17f1f0f2d6e26a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "231bca6c28144f2798c8f3cafac87ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a90c36cce62540c8b859af3c3322d55f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7a28a189cda74647bbbd1a7706f322ae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_479d52965ac44abfa7f1bbc3ac95f856",
              "IPY_MODEL_bf3e02fe63784a9b9a157dffec7b32a3"
            ]
          }
        },
        "7a28a189cda74647bbbd1a7706f322ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "479d52965ac44abfa7f1bbc3ac95f856": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_106550074dd04a98892075fbb1e3c490",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2105d07de35d4721a75dd68f9f0888c0"
          }
        },
        "bf3e02fe63784a9b9a157dffec7b32a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0702f581dfd246b8b3e2e0b257b466f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [42:10&lt;00:00, 174kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1f1a71490314e63a74e82d871277733"
          }
        },
        "106550074dd04a98892075fbb1e3c490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2105d07de35d4721a75dd68f9f0888c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0702f581dfd246b8b3e2e0b257b466f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1f1a71490314e63a74e82d871277733": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0783343c9a44466afa181f3bafdc97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_acfb06aba4f64350b9b863e1e050d0a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_166e60b727c74fe99cbdcde6c2bd563c",
              "IPY_MODEL_7622499aeeb94ef79e02f7a17dc2a46d"
            ]
          }
        },
        "acfb06aba4f64350b9b863e1e050d0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "166e60b727c74fe99cbdcde6c2bd563c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc7f1d61264549f1a98a0fc1701de976",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_249aa030cb7a4f19a5b5ae2fb513422d"
          }
        },
        "7622499aeeb94ef79e02f7a17dc2a46d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_01f0a6101bfa4bb5bd552a4dd43715ff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.71kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67266a07ae1d4332a27d99f7d9dc1d3e"
          }
        },
        "dc7f1d61264549f1a98a0fc1701de976": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "249aa030cb7a4f19a5b5ae2fb513422d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01f0a6101bfa4bb5bd552a4dd43715ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67266a07ae1d4332a27d99f7d9dc1d3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "029b897983a5439287904e9eee374b1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_805c4bf7b7ba48d086169cc6290a7ad1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_561e867302114f948e5d52d322cfffa1",
              "IPY_MODEL_69f1a887c54e42beb1de5738766a0ae8"
            ]
          }
        },
        "805c4bf7b7ba48d086169cc6290a7ad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "561e867302114f948e5d52d322cfffa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d36799ab5de244738913f4d178346c27",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b80e6d79df0a4a8780cf4a65bea71075"
          }
        },
        "69f1a887c54e42beb1de5738766a0ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e3effc3161474980a865d8eb5a375647",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:06&lt;00:00, 66.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f9e0d6e0f6f14a429c22ad6ff026ad2f"
          }
        },
        "d36799ab5de244738913f4d178346c27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b80e6d79df0a4a8780cf4a65bea71075": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3effc3161474980a865d8eb5a375647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f9e0d6e0f6f14a429c22ad6ff026ad2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2412583ee074178921beb0014702858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b71aa9051bd443aabb80d06a4b8d1fe5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5d8ee9a193904ba3bb56400a23cf9cc9",
              "IPY_MODEL_0be0b20156784b62b2e37ecedbd1679a"
            ]
          }
        },
        "b71aa9051bd443aabb80d06a4b8d1fe5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d8ee9a193904ba3bb56400a23cf9cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_69a9a27ba7e14fa7a180a25473d7b1f1",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_75ab849859ea4f9f9393c46b68342cd4"
          }
        },
        "0be0b20156784b62b2e37ecedbd1679a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8a00cd7d30584dc29076e70995a6b73d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 723kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_32ee85331d9e4dceae3c425ee9aa3f64"
          }
        },
        "69a9a27ba7e14fa7a180a25473d7b1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "75ab849859ea4f9f9393c46b68342cd4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8a00cd7d30584dc29076e70995a6b73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "32ee85331d9e4dceae3c425ee9aa3f64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ce00bf9db5f4b098fd7d8e2549c0cc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80aa6f12d1c649b7a8e180a2e43f363f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7be097be49d04627923eeba4fdc56643",
              "IPY_MODEL_6ee72414b5ed490badf084ae0bebecf5"
            ]
          }
        },
        "80aa6f12d1c649b7a8e180a2e43f363f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7be097be49d04627923eeba4fdc56643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0d20e42084aa475ab2f46d31a51aee78",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55cb93e1d38e406388e2cab37f484c38"
          }
        },
        "6ee72414b5ed490badf084ae0bebecf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_45b5201296bb45b79871900df6a968e3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.19MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dd949c8fd41a40978d00f78b89ef4cfc"
          }
        },
        "0d20e42084aa475ab2f46d31a51aee78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55cb93e1d38e406388e2cab37f484c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45b5201296bb45b79871900df6a968e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dd949c8fd41a40978d00f78b89ef4cfc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d7b96d266a364ea3bf95af1ccb1e4585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7ad72fc794024eafb91ecec2b8d67b36",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3143e6cffd004154b69dad63f33ac2b9",
              "IPY_MODEL_686bb5668dda45f08df0f11cd2bbeb08"
            ]
          }
        },
        "7ad72fc794024eafb91ecec2b8d67b36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3143e6cffd004154b69dad63f33ac2b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_51c9561af56b4842984b1103d3df6ccd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bd809fe270424fc794b130edaad72c5e"
          }
        },
        "686bb5668dda45f08df0f11cd2bbeb08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b84a821d80344b819523e50618f7cfe6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 1.01kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95dbf17086604ea0b04870328a9fe2b7"
          }
        },
        "51c9561af56b4842984b1103d3df6ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bd809fe270424fc794b130edaad72c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b84a821d80344b819523e50618f7cfe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95dbf17086604ea0b04870328a9fe2b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7780be71e4754c23b91b8157556d9884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95415322dae14459a8b2d3c2bc92d2cf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1c91ff5c219043e09ebd0178bcbe3221",
              "IPY_MODEL_708cd865b6124a3683f2d0998b418c1d"
            ]
          }
        },
        "95415322dae14459a8b2d3c2bc92d2cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c91ff5c219043e09ebd0178bcbe3221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_badad5fe8ec24d4faa3324f2b6fc0ef8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48d56b160f04494a80370e2fb13ac323"
          }
        },
        "708cd865b6124a3683f2d0998b418c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6540b074427e4c27a1463acd74b4d230",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:54&lt;00:00, 9.18MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba2af4ee414946c994311a3b540b8865"
          }
        },
        "badad5fe8ec24d4faa3324f2b6fc0ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48d56b160f04494a80370e2fb13ac323": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6540b074427e4c27a1463acd74b4d230": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba2af4ee414946c994311a3b540b8865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UopcBh2tB-Y9"
      },
      "source": [
        "##Loading all the Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UHlFcuGCQQ_",
        "outputId": "61804f68-ae9c-433d-e7bb-deb4f715bbe9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4NnEULSGlJ3",
        "outputId": "3634e2fd-8a6e-465e-be55-e9a1007854e3"
      },
      "source": [
        "!pip install transformers==3.5.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers==3.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (0.8)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (4.41.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.12.4)\n",
            "Collecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (20.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.5.1) (2.23.0)\n",
            "Collecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 42.3MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.1) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers==3.5.1) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.5.1) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2020.11.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.5.1) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.5.1) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=fe738906e00c5c2ace1e047302f8ac56519bbb0ec6381086b50e3026b4e80f9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbo2-t7X54RS"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import tqdm\n",
        "import pickle\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Torch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils import data\n",
        "from torch.utils.data import DataLoader\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import random_split\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import RandomSampler\n",
        "from torch.utils.data import SequentialSampler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "#Transformers\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "#Data\n",
        "from sklearn.datasets import fetch_20newsgroups"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6V03lVB8jHc"
      },
      "source": [
        "## Task 1: Classification using BERT or BERT variations "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjWTOgGFCBDY"
      },
      "source": [
        "####Preparing the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw7uOsio4yny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1bfd52d-579e-4f12-d0c7-cf2eb9ac96af"
      },
      "source": [
        "#Train and test dataset\n",
        "train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
        "test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k75hhn__b6NC"
      },
      "source": [
        "params = dict(\n",
        "  seed_val = 1234,\n",
        "  batch_size = 16,\n",
        "  path = r'/content/drive/MyDrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_UIHvr0RVeF"
      },
      "source": [
        "#Train\n",
        "df_train = pd.DataFrame()\n",
        "df_train['data'] = train.data\n",
        "df_train['labels'] = train.target\n",
        "#Test\n",
        "df_test = pd.DataFrame()\n",
        "df_test['data'] = test.data\n",
        "df_test['labels'] = test.target\n",
        "#df_train.shape, df_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfFL8xcoqC32"
      },
      "source": [
        "#Train\n",
        "sentences_train = df_train.data.values\n",
        "labels_train = df_train.labels.values\n",
        "#Test\n",
        "sentences_test = df_test.data.values\n",
        "labels_test = df_test.labels.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "5f5076bb1bd74930881fb9d380b3a01f",
            "46416536060e4425bb0d7a32fb3767bd",
            "b5ae265bc9d349f897af9b48a57ef672",
            "1253aa8e39644b4289adca15c948ae16",
            "8be4a9b317364a01bf9b8775356c2094",
            "8ef5641d72da46f99f60651441a5b2a9",
            "d9fc0c7eb7174d85b42d02fd525dbf34",
            "5135f004b7fa471f824a70c9b8010409"
          ]
        },
        "id": "xKDX9v2_qC_-",
        "outputId": "b50f8a66-cd80-4a60-a319-cbe4c7693e37"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f5076bb1bd74930881fb9d380b3a01f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4epkiZrqDJ3",
        "outputId": "8134be3c-6118-4f0d-f988-95a3170385be"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences_train[0])\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences_train[0]))\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences_train[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Tokenized:  ['i', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'en', '##light', '##en', 'me', 'on', 'this', 'car', 'i', 'saw', 'the', 'other', 'day', '.', 'it', 'was', 'a', '2', '-', 'door', 'sports', 'car', ',', 'looked', 'to', 'be', 'from', 'the', 'late', '60s', '/', 'early', '70s', '.', 'it', 'was', 'called', 'a', 'brick', '##lin', '.', 'the', 'doors', 'were', 'really', 'small', '.', 'in', 'addition', ',', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', '.', 'this', 'is', 'all', 'i', 'know', '.', 'if', 'anyone', 'can', 'tell', '##me', 'a', 'model', 'name', ',', 'engine', 'spec', '##s', ',', 'years', 'of', 'production', ',', 'where', 'this', 'car', 'is', 'made', ',', 'history', ',', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', ',', 'please', 'e', '-', 'mail', '.']\n",
            "Token IDs:  [1045, 2001, 6603, 2065, 3087, 2041, 2045, 2071, 4372, 7138, 2368, 2033, 2006, 2023, 2482, 1045, 2387, 1996, 2060, 2154, 1012, 2009, 2001, 1037, 1016, 1011, 2341, 2998, 2482, 1010, 2246, 2000, 2022, 2013, 1996, 2397, 20341, 1013, 2220, 17549, 1012, 2009, 2001, 2170, 1037, 5318, 4115, 1012, 1996, 4303, 2020, 2428, 2235, 1012, 1999, 2804, 1010, 1996, 2392, 21519, 2001, 3584, 2013, 1996, 2717, 1997, 1996, 2303, 1012, 2023, 2003, 2035, 1045, 2113, 1012, 2065, 3087, 2064, 2425, 4168, 1037, 2944, 2171, 1010, 3194, 28699, 2015, 1010, 2086, 1997, 2537, 1010, 2073, 2023, 2482, 2003, 2081, 1010, 2381, 1010, 2030, 3649, 18558, 2017, 2031, 2006, 2023, 24151, 2559, 2482, 1010, 3531, 1041, 1011, 5653, 1012]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uM9MuD07sQ0z"
      },
      "source": [
        "####All the necessary Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyFJmGqizwXl"
      },
      "source": [
        "#Tokenizer and preprcessing\n",
        "def tokenizer_s(sentences, max_len):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in sentences:\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      \n",
        "                          add_special_tokens = True, \n",
        "                          max_length = max_len,          \n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   \n",
        "                          return_tensors = 'pt',     \n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNyYT4Qr9j_3"
      },
      "source": [
        "#data loaders function\n",
        "\n",
        "def loaders(sentences_train, labels_train, sentences_test, labels_test, max_len, batch_size):\n",
        "  input_ids_train, attention_masks_train, input_ids_test, attention_masks_test, labels_train, labels_test = sentences_t(sentences_train, labels_train, sentences_test, labels_test, max_len)\n",
        "\n",
        "  train_dataset = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "  test_dataset = TensorDataset(input_ids_test, attention_masks_test, labels_test)\n",
        "\n",
        "  train_dataloader = DataLoader(\n",
        "              train_dataset,\n",
        "              sampler = RandomSampler(train_dataset),\n",
        "              batch_size = batch_size\n",
        "          )\n",
        "\n",
        "  validation_dataloader = DataLoader(\n",
        "              test_dataset, \n",
        "              sampler = SequentialSampler(test_dataset),\n",
        "              batch_size = batch_size\n",
        "          )\n",
        "  return train_dataloader, validation_dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3pGPjzyMqe4"
      },
      "source": [
        "#Sentences to Tokens conversion\n",
        "def sentences_t(sentences_train, labels_train, sentences_test, labels_test, max_len): \n",
        "  input_ids_train, attention_masks_train = tokenizer_s(sentences_train, max_len)\n",
        "  labels_train = torch.tensor(labels_train)\n",
        "\n",
        "  input_ids_test, attention_masks_test = tokenizer_s(sentences_test, max_len)\n",
        "  labels_test = torch.tensor(labels_test)\n",
        "\n",
        "  # Print sentence 0, now as a list of IDs.\n",
        "  print('Original: ', sentences_train[0])\n",
        "  print('Token IDs:', input_ids_train[0].shape)\n",
        "  \n",
        "  return input_ids_train, attention_masks_train, input_ids_test, attention_masks_test, labels_train, labels_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jj7EKHaYDPWg"
      },
      "source": [
        "#Train loop\n",
        "def train_loop(model, train_dataloader, validation_dataloader, optimizer, scheduler, epochs, seed, device):\n",
        "\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "  train_losses= np.zeros(epochs)\n",
        "  valid_losses= np.zeros(epochs)\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    \n",
        "    t0= datetime.now()\n",
        "    train_loss=[]\n",
        "    \n",
        "    model.train()\n",
        "    for batch in train_dataloader:\n",
        "    \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "      # forward pass\n",
        "      \n",
        "      loss, logits = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "      \n",
        "      # set gradients to zero \n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # backward pass\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "      train_loss.append(loss.item())\n",
        "    \n",
        "    train_loss=np.mean(train_loss)\n",
        "        \n",
        "    valid_loss=[]\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      for batch in validation_dataloader:\n",
        "  \n",
        "        # forward pass\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask, \n",
        "                            labels=b_labels)\n",
        "        \n",
        "        valid_loss.append(loss.item())\n",
        "\n",
        "      valid_loss=np.mean(valid_loss)\n",
        "    \n",
        "    # save Losses\n",
        "    train_losses[epoch]= train_loss\n",
        "    valid_losses[epoch]= valid_loss\n",
        "    dt= datetime.now()-t0\n",
        "    print(f'Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}    Valid Loss: {valid_loss:.4f}, Duration: {dt}')\n",
        "\n",
        "  return train_losses, valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTfuUDafFuiv"
      },
      "source": [
        "# Accuracy- write a function to get accuracy\n",
        "# use this function to get accuracy and print accuracy\n",
        "def get_accuracy(data_iter, model, device):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    correct =0 \n",
        "    total =0\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "    # forward pass\n",
        "\n",
        "      loss, logits = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "\n",
        "      _,indices = torch.max(logits,dim=1)\n",
        "      correct+= (b_labels==indices).sum().item()\n",
        "      total += b_labels.shape[0]\n",
        "    \n",
        "    acc= correct/total\n",
        "\n",
        "    return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3r6Z-UwFvgX"
      },
      "source": [
        "# Write a function to get predictions\n",
        "def get_predictions(data_iter, model):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    predictions= np.array([])\n",
        "    y_test= np.array([])\n",
        "\n",
        "    for batch in data_iter:\n",
        "      \n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "    # forward pass\n",
        "\n",
        "      loss, logits = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "      \n",
        "      _,indices = torch.max(logits,dim=1)\n",
        "      predictions=np.concatenate((predictions,indices.cpu().numpy())) \n",
        "      y_test = np.concatenate((y_test,b_labels.cpu().numpy())) \n",
        "      \n",
        "  return y_test, predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRYLxH4S-mCQ"
      },
      "source": [
        "def model_parameters(model):\n",
        "  epochs = 2\n",
        "  no_decay = ['bias', 'LayerNorm.weight']\n",
        "  optimizer_grouped_parameters = [\n",
        "          {'params': [p for n, p in model.named_parameters() \n",
        "            if not any(nd in n for nd in no_decay)], \n",
        "          'weight_decay': 0.5},\n",
        "\n",
        "          {'params': [p for n, p in model.named_parameters() \n",
        "          if any(nd in n for nd in no_decay)], \n",
        "          'weight_decay': 0.0}\n",
        "          ]\n",
        "\n",
        "  optimizer = AdamW(optimizer_grouped_parameters,\n",
        "                    lr = 5e-5, \n",
        "                    eps = 1e-8\n",
        "                  )\n",
        "  \n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                              num_warmup_steps = 0,\n",
        "                                              num_training_steps = len(train_dataloader) * epochs)\n",
        "  \n",
        "  return epochs, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIPuGyXjLxLN"
      },
      "source": [
        "  device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFwty2aQJXcz"
      },
      "source": [
        "### EXPERIMENT 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mz0m1t6YqXux"
      },
      "source": [
        "####BERT Model with 512 tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8dMepPbqDSG",
        "outputId": "ab440335-aeb3-4863-ba45-217285eb25ad"
      },
      "source": [
        "params['max_len'] = 0\n",
        "for i,sent in enumerate(sentences_train):\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    params['max_len'] = max(params['max_len'], len(input_ids))\n",
        "print('Max sentence length: ', params['max_len'])\n",
        "params['max_len'] = 512"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (604 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Max sentence length:  52886\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU_PF1HiqhxN",
        "outputId": "be431f25-881e-431f-9aa6-2b6b671a070e"
      },
      "source": [
        "#Train Data Loader\n",
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "0367fa064d5a4942aba0bfee2f5aa0b0",
            "f7fba19c6cfc4702a3117b70b5d79ff3",
            "1992c17ce4844c3ea229c9de1fe0b312",
            "c18a08b476794fbba72019ed0793c797",
            "0490b885ee9d4e2d908fd91a5afea4e6",
            "07d43af87346420b98bc55010b8b4952",
            "30a0f0aefc054ef49e17f1f0f2d6e26a",
            "231bca6c28144f2798c8f3cafac87ff6",
            "a90c36cce62540c8b859af3c3322d55f",
            "7a28a189cda74647bbbd1a7706f322ae",
            "479d52965ac44abfa7f1bbc3ac95f856",
            "bf3e02fe63784a9b9a157dffec7b32a3",
            "106550074dd04a98892075fbb1e3c490",
            "2105d07de35d4721a75dd68f9f0888c0",
            "0702f581dfd246b8b3e2e0b257b466f6",
            "d1f1a71490314e63a74e82d871277733"
          ]
        },
        "id": "1bchdtwcqhxO",
        "outputId": "558077d8-43b7-4e53-fcc2-017898c51c60"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0367fa064d5a4942aba0bfee2f5aa0b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a90c36cce62540c8b859af3c3322d55f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTDDBB-2qhxP"
      },
      "source": [
        "#Parameters\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1R8OEWB2qhxP"
      },
      "source": [
        "params['epochs'], params['optimizer'],  params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXY-YdGOqhxP"
      },
      "source": [
        "model.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0VXNKYmqhxP",
        "outputId": "9a92b8e3-c92c-4f0e-d034-1ea4bbeda6b3"
      },
      "source": [
        "#Train Loss and Validation loss\n",
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.8773    Valid Loss: 2.7825, Duration: 0:12:14.064195\n",
            "Epoch 2/2, Train Loss: 2.7270    Valid Loss: 2.6938, Duration: 0:12:19.591873\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWjrfjBgqhxQ",
        "outputId": "d99f4830-47b9-40d9-9740-dc4a9af5e2b9"
      },
      "source": [
        "#Getting accuracies\n",
        "train_acc = get_accuracy(train_dataloader, model,device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model,device)\n",
        "print(\"Train acc: \",train_acc,\"Valid acc: \", valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc:  0.25799893936715573 Valid acc:  0.2457514604354753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i--hFY4c-WhZ"
      },
      "source": [
        "####BERT Model with 128 tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3iGi7N3zocf"
      },
      "source": [
        "params['max_len'] = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tylmd0mq9G5Z",
        "outputId": "cf9564ae-5f66-45e6-cf96-3a7a35a480b4"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTyJ7gNp-Xn0",
        "outputId": "53c352b9-d375-4615-cdfb-e27dd5ae3f5b"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fglQKEWDFkZQ"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x9vGyC6_od4"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRl4JO2LSoLI"
      },
      "source": [
        "#Training\n",
        "model.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVCbWX9WF4Nv",
        "outputId": "eb6775e5-0def-485d-b12a-0d44e20d0967"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.8839    Valid Loss: 2.7787, Duration: 0:02:43.894216\n",
            "Epoch 2/2, Train Loss: 2.7245    Valid Loss: 2.6867, Duration: 0:02:43.378686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoQFo9U2lz6V",
        "outputId": "7ff88fc4-ae55-4470-e64a-db6625ed3346"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model,device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(train_acc, valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2647162807141594 0.2624800849707913\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uip6GhzDOtEj"
      },
      "source": [
        "#### BERT Model with 140 tokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99PK0_RZOtEk"
      },
      "source": [
        "params['max_len'] = 140"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL0GganSOtEl",
        "outputId": "fddbf5f2-d3d0-4b85-e082-0ebecb3e97a5"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([140])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lB4E8QJoOtEl",
        "outputId": "b18260a8-88af-48c7-f02c-501500a7ff1b"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0TzazZhOtEl"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diz5oGsQOtEl"
      },
      "source": [
        "params['epochs'], params['optimizer'],  params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHgt6ktjOtEl",
        "outputId": "0c414b63-d8f7-453e-d77c-0d24ce736655"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.8841    Valid Loss: 2.7832, Duration: 0:03:09.593033\n",
            "Epoch 2/2, Train Loss: 2.7236    Valid Loss: 2.6880, Duration: 0:03:08.959613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Va_TCiSmZD7",
        "outputId": "b3d78dc1-cd7d-4102-b883-64bdbbcdc214"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(train_acc, valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2672794767544635 0.2627456186935741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DebbPsjET71d"
      },
      "source": [
        "#### BERT Model 4 by truncating from the end"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h0qgBp5UNTX"
      },
      "source": [
        "def tokenizer_s(sentences, max_len):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in sentences:\n",
        "      sent = sent.split(\" \")\n",
        "      sent.reverse()\n",
        "      sent = \" \".join(sent)\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                    \n",
        "                          add_special_tokens = True,\n",
        "                          max_length = max_len,          \n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   \n",
        "                          return_tensors = 'pt',    \n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSkSCeuqVHln"
      },
      "source": [
        "params['max_len'] = 140"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJtHispeVHlo",
        "outputId": "05c0c9b8-e2d7-4453-d33c-500be7061a5c"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([140])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FCTJOXaVHlq",
        "outputId": "144258d9-0015-4501-88ce-bf20fc66ef9a"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfuznjgkVHlq"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZgtKrzoVHlq"
      },
      "source": [
        "params['epochs'],  params['optimizer'],  params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUGenX2nVHlr",
        "outputId": "2b151c47-eb11-431d-b1b2-b80889ba30dd"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.8720    Valid Loss: 2.7455, Duration: 0:03:09.559264\n",
            "Epoch 2/2, Train Loss: 2.7120    Valid Loss: 2.6613, Duration: 0:03:08.964845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU0M2E_o2CB7",
        "outputId": "4f7fa27a-4ebc-4fce-9bfb-0c026b4f99c7"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(\"Train acc:\", train_acc, \"Valid acc:\", valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.27346650167933534 Valid acc: 0.2705788635156665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-36pMc8CrAf"
      },
      "source": [
        "#####For Sequence length, 128"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTLgBtgJCrAg"
      },
      "source": [
        "params['max_len'] = 128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is81KKM6CrAh",
        "outputId": "97da3119-ff6f-4710-eaa8-2d3e8d248f7e"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efHUOOO1CrAj",
        "outputId": "0907e6a3-1792-4464-c680-d4c5904fb829"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxCCtcfDCrAj"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCmgrFrECrAj"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5frN0LMSCrAk",
        "outputId": "a77129db-53f5-4f01-a02a-80b3a98f314f"
      },
      "source": [
        "#Train valid loss\n",
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.8730    Valid Loss: 2.7592, Duration: 0:02:41.486860\n",
            "Epoch 2/2, Train Loss: 2.7193    Valid Loss: 2.6702, Duration: 0:02:42.259626\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auvliWkSCrAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017282d0-0a00-49e5-be6e-5e377826e2b1"
      },
      "source": [
        "#Train valid accuracy\n",
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model,device)\n",
        "print(\"Train acc:\", train_acc,\"Valid acc:\", valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.27196393848329503 Valid acc: 0.2586298459904408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do4uQoqSCrw4"
      },
      "source": [
        "#####For Sequence length, 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aB5NKpuOCrw4"
      },
      "source": [
        "params['max_len'] = 512"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQw-kUfKCrw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4589a58-c914-4d88-d244-9e2bf7b325c1"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnmjVwJbCrw5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5facb84f-1695-443f-ca5f-4c4c869eef90"
      },
      "source": [
        "#Model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J49pwEeCrw5"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECr2y8aMCrw6"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XARaeuWUCrw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6bf2052-1a8a-42cd-9427-0e1d2ea6b763"
      },
      "source": [
        "#Train valid loss\n",
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.8569    Valid Loss: 2.7333, Duration: 0:12:16.321910\n",
            "Epoch 2/2, Train Loss: 2.6893    Valid Loss: 2.6386, Duration: 0:12:17.209193\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSAkzsbSCrw6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30be5ebd-ea9b-4495-b368-6c82c355864b"
      },
      "source": [
        "#train valid accuracy\n",
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(\"Train acc:\", train_acc, \"Valid acc:\",valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train acc: 0.2864592540215662 Valid acc: 0.2831917153478492\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NkTwyRXBC18"
      },
      "source": [
        "#### BERT Model - Truncating from the mid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Hidqk-hBC19"
      },
      "source": [
        "def tokenizer_s(sentences, max_len):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in sentences:\n",
        "      sent = sent.split(\" \")\n",
        "      sent.reverse()\n",
        "      sent = \" \".join(sent)\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      \n",
        "                          add_special_tokens = True, \n",
        "                          max_length = max_len,          \n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   \n",
        "                          return_tensors = 'pt',     \n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DalGMsBnDgpZ"
      },
      "source": [
        "#####For Sequence length, 140"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysy1sYMMBC18"
      },
      "source": [
        "params['max_len'] = 140"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rPhtet4BC19",
        "outputId": "5bfada9c-a4a0-49a9-f3fa-c4e95dc69c25"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([140])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jqLN5oYBC1_",
        "outputId": "08175583-ce84-49e0-a99f-502a7d19d853"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVIANA01BC1_"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wua6vCpLBC2A"
      },
      "source": [
        "params['epochs'], params['optimizer'],  params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBqv0qb-BC2A",
        "outputId": "59f712d7-eb26-4cc4-9e44-4bf886db10ed"
      },
      "source": [
        "#Train valid loss\n",
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.8720    Valid Loss: 2.7455, Duration: 0:03:02.680551\n",
            "Epoch 2/2, Train Loss: 2.7120    Valid Loss: 2.6613, Duration: 0:03:09.193130\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t35SqI_gBC2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a184e503-4220-429c-f81d-01d4c955ec38"
      },
      "source": [
        "#Train valid accuracy\n",
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model,device)\n",
        "print(\"Train accuracy:\",train_acc, \"Valid accuracy:\",valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.27346650167933534 Valid accuracy: 0.2705788635156665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErhSYU6lDxlX"
      },
      "source": [
        "#### Chunking"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBH5yuwmDztq"
      },
      "source": [
        "def chunking(sentences, labels, max_length):\n",
        "  final_sentences = []\n",
        "  final_labels = []\n",
        "  order = []\n",
        "  for target_order, (sent, label) in enumerate(zip(sentences, labels)):\n",
        "    sent = sent.split(\" \")\n",
        "    length = len(sent)\n",
        "    parts = math.ceil(length/max_length)\n",
        "    for i in range(1, parts + 1):\n",
        "      chunk = \" \".join(sent[max_length*(i-1) : max_length*i])\n",
        "      final_sentences.append(chunk)\n",
        "      final_labels.append(label)\n",
        "      order.append(target_order)\n",
        "  # return final_sentences, final_labels, order\n",
        "  return np.array(final_sentences), np.array(final_labels), np.array(order)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WezH9BbC-dYZ"
      },
      "source": [
        "params['max_length'] = 140\n",
        "sentences_train_chunked, labels_train_chunked, order_train = chunking(sentences_train, labels_train, params['max_length'])\n",
        "sentences_test_chunked, labels_test_chunked, order_test = chunking(sentences_test, labels_test, params['max_length'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkzFsniF-dV0"
      },
      "source": [
        "#Creating the model\n",
        "def tokenize_s(sentences, max_len):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in sentences:\n",
        "      sent = sent.split(\" \")\n",
        "      sent = preprocessing(sent, max_len)\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = max_len,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbcVV5Ie-dT0"
      },
      "source": [
        "def processing(sent, max_len):\n",
        "  return sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lyu6QgA7-1sL"
      },
      "source": [
        "#####For sequence length, 140"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZBgkb2w-dO7",
        "outputId": "0f87ab56-52c1-459b-d68c-6578b231fa62"
      },
      "source": [
        "params['max_len'] = 140\n",
        "train_dataloader, validation_dataloader = loaders(sentences_train_chunked, labels_train_chunked, sentences_test_chunked, \n",
        "                                                       labels_test_chunked, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([140])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "f0783343c9a44466afa181f3bafdc97a",
            "acfb06aba4f64350b9b863e1e050d0a1",
            "166e60b727c74fe99cbdcde6c2bd563c",
            "7622499aeeb94ef79e02f7a17dc2a46d",
            "dc7f1d61264549f1a98a0fc1701de976",
            "249aa030cb7a4f19a5b5ae2fb513422d",
            "01f0a6101bfa4bb5bd552a4dd43715ff",
            "67266a07ae1d4332a27d99f7d9dc1d3e",
            "029b897983a5439287904e9eee374b1b",
            "805c4bf7b7ba48d086169cc6290a7ad1",
            "561e867302114f948e5d52d322cfffa1",
            "69f1a887c54e42beb1de5738766a0ae8",
            "d36799ab5de244738913f4d178346c27",
            "b80e6d79df0a4a8780cf4a65bea71075",
            "e3effc3161474980a865d8eb5a375647",
            "f9e0d6e0f6f14a429c22ad6ff026ad2f"
          ]
        },
        "id": "mP5BDyqX-dL7",
        "outputId": "4721b319-a988-4904-d196-846647c7d291"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0783343c9a44466afa181f3bafdc97a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "029b897983a5439287904e9eee374b1b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoJeb62r-dFw"
      },
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.classifier.weight.requires_grad = True\n",
        "model.classifier.bias.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XoVOZA6-8aq"
      },
      "source": [
        "params['epochs'], params['optimizer'],  params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_FyRuAG_CWF",
        "outputId": "b570a79c-1a7b-40c1-c597-89896da69b5f"
      },
      "source": [
        " train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'], 1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.9801    Valid Loss: 2.9615, Duration: 0:05:35.546815\n",
            "Epoch 2/2, Train Loss: 2.9582    Valid Loss: 2.9563, Duration: 0:05:46.537441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxe_UuvM_CS1"
      },
      "source": [
        "def get_chunk_accuracy(model, data_iter, order, device):\n",
        "  predictions = []\n",
        "  correct_labels = []\n",
        "\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    for batch in data_iter:\n",
        "\n",
        "      b_input_ids = batch[0].to(device)\n",
        "      b_input_mask = batch[1].to(device)\n",
        "      b_labels = batch[2].to(device)\n",
        "    # forward pass\n",
        "\n",
        "      loss, logits = model(b_input_ids, \n",
        "                          token_type_ids=None, \n",
        "                          attention_mask=b_input_mask, \n",
        "                          labels=b_labels)\n",
        "\n",
        "      _,indices = torch.max(logits,dim=1)\n",
        "\n",
        "      indices = indices.cpu().numpy()\n",
        "      predictions += list(indices)\n",
        "      b_labels = b_labels.cpu().numpy()\n",
        "      correct_labels += list(b_labels)\n",
        "\n",
        "  return predictions, correct_labels, order"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxhmQCmi_CP6"
      },
      "source": [
        "predictions, correct_labels, order = get_chunk_accuracy(model, validation_dataloader, order_test, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkSx_UwO_Pbg",
        "outputId": "75dfdd15-e322-45f1-e863-1998671c7ac6"
      },
      "source": [
        "state = pd.DataFrame({'order':order, 'preds':predictions,'correct':correct_labels})\n",
        "state_2 = state.groupby('order').agg(lambda x:x.value_counts().index[0])\n",
        "state_2[state_2['preds']==state_2['correct']].shape[0]/state['order'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.06120552310143388"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxfoVr9O_PVC"
      },
      "source": [
        "del sentences_train_chunked, labels_train_chunked, order_train, sentences_test_chunked, labels_test_chunked, order_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIw8me0-_THK",
        "outputId": "ed788fc1-bfc9-443a-f023-8c359bce7b4d"
      },
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "222"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-toFFTw9QZrs"
      },
      "source": [
        "In experiment 1, after reducing the sequence length from 512 we observe 1% improvement in the accuracy of the model whereas 'truncating the model from end' & 'truncating the model from mid' gives us the same accuracy as the one observed after reducing the sequence length. In case of chunking we observe significant reduction of 20% in comparsion to other model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jU-bp-aD0cX"
      },
      "source": [
        "## TASK 2 - Fine tune Bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBLrJhiuDzN2"
      },
      "source": [
        "def tokenize_s(sentences, max_len):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in sentences:\n",
        "      sent = sent.split(\" \")\n",
        "      sent.reverse()\n",
        "      sent = \" \".join(sent)\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      \n",
        "                          add_special_tokens = True, \n",
        "                          max_length = max_len,          \n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   \n",
        "                          return_tensors = 'pt',     \n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3a4qVEsE_NJ"
      },
      "source": [
        "##### Sequence Length, 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pe_ziG8yu8vA"
      },
      "source": [
        "params['max_len'] = 512\n",
        "params['batch_size'] = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0HNBVZmE8gs",
        "outputId": "75700a1f-b445-4fa3-efe1-068777a5cc9b"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBPlSl8BFVkI",
        "outputId": "d3e2cd4f-2ff8-49ae-cca3-d165c0b76ee2"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXzg4pjxF3IO",
        "outputId": "ce56ba3d-b479-4a67-eeed-dde86287b811"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |     858 MB |    7938 MB |  107110 GB |  107109 GB |\n",
            "|       from large pool |     857 MB |    7936 MB |  107088 GB |  107087 GB |\n",
            "|       from small pool |       1 MB |      21 MB |      22 GB |      22 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |     858 MB |    7938 MB |  107110 GB |  107109 GB |\n",
            "|       from large pool |     857 MB |    7936 MB |  107088 GB |  107087 GB |\n",
            "|       from small pool |       1 MB |      21 MB |      22 GB |      22 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |     924 MB |    8234 MB |    8664 MB |    7740 MB |\n",
            "|       from large pool |     922 MB |    8206 MB |    8636 MB |    7714 MB |\n",
            "|       from small pool |       2 MB |      28 MB |      28 MB |      26 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   67086 KB |  261595 KB |   27587 GB |   27587 GB |\n",
            "|       from large pool |   66130 KB |  259666 KB |   27564 GB |   27564 GB |\n",
            "|       from small pool |     956 KB |    7075 KB |      22 GB |      22 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     405    |    1066    |    8230 K  |    8229 K  |\n",
            "|       from large pool |     150    |     496    |    5096 K  |    5096 K  |\n",
            "|       from small pool |     255    |     714    |    3133 K  |    3133 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     405    |    1066    |    8230 K  |    8229 K  |\n",
            "|       from large pool |     150    |     496    |    5096 K  |    5096 K  |\n",
            "|       from small pool |     255    |     714    |    3133 K  |    3133 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      51    |     246    |     264    |     213    |\n",
            "|       from large pool |      50    |     232    |     250    |     200    |\n",
            "|       from small pool |       1    |      14    |      14    |      13    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      44    |      59    |    3482 K  |    3482 K  |\n",
            "|       from large pool |      25    |      33    |    2465 K  |    2465 K  |\n",
            "|       from small pool |      19    |      31    |    1016 K  |    1016 K  |\n",
            "|===========================================================================|\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BDWSZGqF_Bf",
        "outputId": "9e154197-1db5-4bd3-8c35-343347b783ab"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'],1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 1.0224    Valid Loss: 1.1226, Duration: 0:23:04.048650\n",
            "Epoch 2/2, Train Loss: 1.0085    Valid Loss: 1.1113, Duration: 0:23:30.232013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abNlxRFgGIPO",
        "outputId": "31c064d0-e8f4-4a60-d907-29b86ac71a10"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(\"Train accuracy:\", train_acc, \"Valid Accuracy:\" ,valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.782440232714563428 Valid Accuracy: 0.6912464132147456348\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LcvtVdPP5cW"
      },
      "source": [
        "After fine-tuning the model we observe significant improvement in both training and validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnO_a9XpG7uC"
      },
      "source": [
        "## TASK 3 - Different BERT variations from Huggingface library "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TpVZqLCIDV_"
      },
      "source": [
        "### ALBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kqd6gpsBIa_"
      },
      "source": [
        "from transformers import AlbertTokenizer, AlbertForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WL-Oi4j2HG-p"
      },
      "source": [
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiT6heprHLHO"
      },
      "source": [
        "def tokenize_s(sentences, max_len):\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  for sent in sentences:\n",
        "      sent = sent.split(\" \")\n",
        "      sent.reverse()\n",
        "      sent = \" \".join(sent)\n",
        "      encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,                      # Sentence to encode.\n",
        "                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                          max_length = max_len,           # Pad & truncate all sentences.\n",
        "                          pad_to_max_length = True,\n",
        "                          return_attention_mask = True,   # Construct attn. masks.\n",
        "                          return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                    )\n",
        "      \n",
        "      # Add the encoded sentence to the list.    \n",
        "      input_ids.append(encoded_dict['input_ids'])\n",
        "      \n",
        "      # And its attention mask (simply differentiates padding from non-padding).\n",
        "      attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "  # Convert the lists into tensors.\n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "  return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djDCdeoOHbWM"
      },
      "source": [
        "##### Sequence Length, 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fF1Pq9VHU1P"
      },
      "source": [
        "params['max_len'] = 512\n",
        "params['batch_size'] = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xab2AtmcHgs6",
        "outputId": "60579455-4c15-4a19-a20c-8dacb1ed9b91"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-nIc-8THnMY",
        "outputId": "f177e2a4-52f7-4daf-a3ed-c7b258e9eccc"
      },
      "source": [
        "model = AlbertForSequenceClassification.from_pretrained(\n",
        "    \"albert-base-v2\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBhZ1PYrP-g9"
      },
      "source": [
        "**Without Fine-tunning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jj6A1entZ7_V",
        "outputId": "a58b5116-3e06-41bd-ef30-bef87e7b2226"
      },
      "source": [
        "model = AlbertForSequenceClassification.from_pretrained(\n",
        "    \"albert-base-v2\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at albert-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOtEfIebOlnl"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "  param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Hf6-9toOqJT"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPuwZQs9Ouv6",
        "outputId": "2d7ce064-3dc4-4a34-9c9d-437146fe9bff"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'],1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.9722    Valid Loss: 2.9379, Duration: 0:11:57.462271\n",
            "Epoch 2/2, Train Loss: 2.9219    Valid Loss: 2.9135, Duration: 0:11:58.317175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsBWFV6dOv86",
        "outputId": "a8c32a03-5dc7-4224-90f4-ae00f2be4a7b"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(\"Train accuracy:\", train_acc, \"Valid Accuracy:\" ,valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.1251546756231218 Valid Accuracy: 0.12705788635156665\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tZcgmxIwkFf"
      },
      "source": [
        "**With Fine-Tunning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6mW9h6QwkFg"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9FFt2C_wkFg",
        "outputId": "e80beec8-610f-476d-a7c3-4a754a7f8c63"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'],1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 1.6314    Valid Loss: 1.2753, Duration: 0:23:53.068745\n",
            "Epoch 2/2, Train Loss: 0.9262    Valid Loss: 1.1068, Duration: 0:23:54.198061\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbvdMcRjwkFg",
        "outputId": "1dbf85b8-75f2-494e-ccc0-3e548d316389"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(\"Train accuracy:\", train_acc, \"Valid Accuracy:\" ,valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.7959165635495846 Valid Accuracy: 0.6733935209771641\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_CKyIh_O2XT"
      },
      "source": [
        "In case of \"ALBERTA\" we observe similar results as in case of \"bert-base-uncased\" for fine-tuned model but in case of without fine-tuned model we observe 12% higher accuracy for \"bert-base-uncased\" model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laRGiZRgLoSW"
      },
      "source": [
        "###ROBERTA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "591vBtAwLuzi"
      },
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "b2412583ee074178921beb0014702858",
            "b71aa9051bd443aabb80d06a4b8d1fe5",
            "5d8ee9a193904ba3bb56400a23cf9cc9",
            "0be0b20156784b62b2e37ecedbd1679a",
            "69a9a27ba7e14fa7a180a25473d7b1f1",
            "75ab849859ea4f9f9393c46b68342cd4",
            "8a00cd7d30584dc29076e70995a6b73d",
            "32ee85331d9e4dceae3c425ee9aa3f64",
            "4ce00bf9db5f4b098fd7d8e2549c0cc0",
            "80aa6f12d1c649b7a8e180a2e43f363f",
            "7be097be49d04627923eeba4fdc56643",
            "6ee72414b5ed490badf084ae0bebecf5",
            "0d20e42084aa475ab2f46d31a51aee78",
            "55cb93e1d38e406388e2cab37f484c38",
            "45b5201296bb45b79871900df6a968e3",
            "dd949c8fd41a40978d00f78b89ef4cfc"
          ]
        },
        "id": "l-V3HXlWMTUe",
        "outputId": "0e42b236-5470-45ec-e2db-5d37ff59edc2"
      },
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2412583ee074178921beb0014702858",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ce00bf9db5f4b098fd7d8e2549c0cc0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml0xM88iQO7H"
      },
      "source": [
        "**Sequence Length, 512**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "331VmTjnQRv1"
      },
      "source": [
        "params['max_len'] = 512\n",
        "params['batch_size'] = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hXAIH5hQVGv",
        "outputId": "d051aa3e-7992-4e22-9046-164a4941df40"
      },
      "source": [
        "train_dataloader, validation_dataloader = loaders(sentences_train, labels_train, sentences_test, labels_test, params['max_len'], params['batch_size'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.6/dist-packages/transformers/tokenization_utils_base.py:2022: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  I was wondering if anyone out there could enlighten me on this car I saw\n",
            "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
            "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
            "the front bumper was separate from the rest of the body. This is \n",
            "all I know. If anyone can tellme a model name, engine specs, years\n",
            "of production, where this car is made, history, or whatever info you\n",
            "have on this funky looking car, please e-mail.\n",
            "Token IDs: torch.Size([512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224,
          "referenced_widgets": [
            "d7b96d266a364ea3bf95af1ccb1e4585",
            "7ad72fc794024eafb91ecec2b8d67b36",
            "3143e6cffd004154b69dad63f33ac2b9",
            "686bb5668dda45f08df0f11cd2bbeb08",
            "51c9561af56b4842984b1103d3df6ccd",
            "bd809fe270424fc794b130edaad72c5e",
            "b84a821d80344b819523e50618f7cfe6",
            "95dbf17086604ea0b04870328a9fe2b7",
            "7780be71e4754c23b91b8157556d9884",
            "95415322dae14459a8b2d3c2bc92d2cf",
            "1c91ff5c219043e09ebd0178bcbe3221",
            "708cd865b6124a3683f2d0998b418c1d",
            "badad5fe8ec24d4faa3324f2b6fc0ef8",
            "48d56b160f04494a80370e2fb13ac323",
            "6540b074427e4c27a1463acd74b4d230",
            "ba2af4ee414946c994311a3b540b8865"
          ]
        },
        "id": "bu0vZCclQY6C",
        "outputId": "dccbff74-18be-464a-af59-ac94189ffa35"
      },
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d7b96d266a364ea3bf95af1ccb1e4585",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7780be71e4754c23b91b8157556d9884",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgRHyFTRQctx"
      },
      "source": [
        "**With Fine Tunning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RJLf9HFQev5"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVqtw6JcQfps",
        "outputId": "569ef3e1-c51e-4656-b058-0b947483feef"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'],1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 1.2981    Valid Loss: 1.1378, Duration: 0:23:06.112439\n",
            "Epoch 2/2, Train Loss: 0.7336    Valid Loss: 1.0544, Duration: 0:23:06.559929\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N--BQyouxEpO",
        "outputId": "c0fe5319-ff73-47e4-988a-cc09cbaa0da0"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(\"Train accuracy:\", train_acc, \"Valid Accuracy:\" ,valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.851864946084497 Valid Accuracy: 0.7130908125331917\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMEAaqjNQl3g"
      },
      "source": [
        "**Without Fine Tunning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GhRbwS3CX51",
        "outputId": "5d3542e3-6a37-4efb-cbc0-30e4cea6d22b"
      },
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\n",
        "    \"roberta-base\",\n",
        "    num_labels = 20,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDKRujnbQocc"
      },
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "for param in model.classifier.parameters():\n",
        "  param.requires_grad = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hehAUSIQqdO"
      },
      "source": [
        "params['epochs'], params['optimizer'], params['scheduler'] = model_parameters(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP9jyxTMQsJZ",
        "outputId": "1596ad55-f4e1-4212-c244-bdbbd0811dc5"
      },
      "source": [
        "train_losses, valid_losses = train_loop(model, train_dataloader, validation_dataloader, params['optimizer'], params['scheduler'], params['epochs'],1234, device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Train Loss: 2.9565    Valid Loss: 2.9206, Duration: 0:10:40.283758\n",
            "Epoch 2/2, Train Loss: 2.8939    Valid Loss: 2.8862, Duration: 0:10:40.264726\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYakgHQMQt3F",
        "outputId": "8b518c9b-4b44-4023-ff80-9f920685f982"
      },
      "source": [
        "train_acc = get_accuracy(train_dataloader, model, device)\n",
        "valid_acc = get_accuracy(validation_dataloader, model, device)\n",
        "print(\"Train accuracy:\", train_acc, \"Valid Accuracy:\" ,valid_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 0.35310235106947147 Valid Accuracy: 0.3341741901221455\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNzYNVFTOY94"
      },
      "source": [
        "Conclusion:- After implementing all the experiments we observe that \"ROBERTA\" gives us the best possible validation accuracy for both fine-tuned model and without fine-tuned model of 33.4% & 71.3% respectively. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6_TZ4vtxm3f"
      },
      "source": [
        "#### **-------------------------------------THE END---------------------------------------**"
      ]
    }
  ]
}